{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da98b12",
   "metadata": {},
   "source": [
    "### Importing modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acacd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0172985",
   "metadata": {},
   "source": [
    "### Data Preparation and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee156af",
   "metadata": {},
   "source": [
    "In order to crop the part that contains only the brain of the image, I used a cropping technique to find the extreme top, bottom, left and right points of the brain.(Thanks to the `Image processing`course I took last semester in the university)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7b7cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_brain_contour(image, plot=False):\n",
    "    \n",
    "\n",
    "    # Converting the image to grayscale, and blur it.\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Thresholding the image, and performing erosions + dilations\n",
    "    # to remove noise.\n",
    "    \n",
    "    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh = cv2.erode(thresh, None, iterations=2)\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "    # Finding contours in thresholded image, and grabing the largest one.\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "    \n",
    "\n",
    "    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "    extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
    "    extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "    extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "    \n",
    "    # cropping new image using the using four extreme points.\n",
    "    new_image = image[extTop[1]:extBot[1], extLeft[0]:extRight[0]] \n",
    "    \n",
    "    \n",
    "    # To plot the image.\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image)\n",
    "        \n",
    "        plt.tick_params(axis='both', which='both', \n",
    "                        top=False, bottom=False, left=False, right=False,\n",
    "                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
    "        \n",
    "        plt.title('Original Image')\n",
    "            \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(new_image)\n",
    "\n",
    "        plt.tick_params(axis='both', which='both', \n",
    "                        top=False, bottom=False, left=False, right=False,\n",
    "                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
    "\n",
    "        plt.title('Cropped Image')\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    return new_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e84abde",
   "metadata": {},
   "source": [
    "This is an example of cropped image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9442061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_img = cv2.imread('/home/matin_mrv/Downloads/archive/yes/Y2.jpg')\n",
    "ex_new_img = crop_brain_contour(ex_img, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e562c0f",
   "metadata": {},
   "source": [
    "### Loading the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b032be7",
   "metadata": {},
   "source": [
    "The following function takes two arguments, the first one is a list of directory paths for the folders 'yes' and 'no' that contain the image data and the second argument is the image size, and for every image in both directories we do the following operations:\n",
    "\n",
    "1. Read the image.\n",
    "2. Crop the part of the image representing only the brain.\n",
    "3. Resize the image (because the images in the dataset come in different sizes So, we want all of our images to be (240, 240, 3) to feed it as an input to the neural network.\n",
    "4. Apply normalization because we want pixel values to be scaled to the range 0-1.\n",
    "5. Append the image to X and its label to y.\n",
    "6. Suffle X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec00b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir_list, image_size):\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    image_width, image_height = image_size\n",
    "    \n",
    "    for directory in dir_list:\n",
    "        for filename in listdir(directory):\n",
    "            \n",
    "            image = cv2.imread(directory + '/' + filename)\n",
    "            image = crop_brain_contour(image, plot=False)\n",
    "            image = cv2.resize(image, dsize=(image_width, image_height), interpolation=cv2.INTER_CUBIC)\n",
    "            image = image / 255.\n",
    "            X.append(image)\n",
    "                        \n",
    "            if directory[-3:] == 'yes':\n",
    "                y.append([1])\n",
    "            else:\n",
    "                y.append([0])\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X, y = shuffle(X, y)\n",
    "    \n",
    "    print(f'Number of examples is: {len(X)}')\n",
    "    print(f'X shape is: {X.shape}')\n",
    "    print(f'y shape is: {y.shape}')\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ac7296",
   "metadata": {},
   "source": [
    "Loading the augmented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ee4055",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_yes = '/home/matin_mrv/Desktop/Brain Tumor Detection/augmented_data/yes'\n",
    "augmented_no = '/home/matin_mrv/Desktop/Brain Tumor Detection/augmented_data/yes'\n",
    "\n",
    "IMG_WIDTH, IMG_HEIGHT = (240, 240)\n",
    "\n",
    "X, y = load_data([augmented_yes, augmented_no], (IMG_WIDTH, IMG_HEIGHT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3322ac",
   "metadata": {},
   "source": [
    "# Plot sample images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c108d939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_images(X, y, n=50):\n",
    "\n",
    "    for label in [0,1]:\n",
    "        \n",
    "        images = X[np.argwhere(y == label)]\n",
    "        n_images = images[:n]\n",
    "        \n",
    "        columns_n = 10\n",
    "        rows_n = int(n/ columns_n)\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        \n",
    "        i = 1      \n",
    "        for image in n_images:\n",
    "            plt.subplot(rows_n, columns_n, i)\n",
    "            plt.imshow(image[0])\n",
    "            \n",
    "            plt.tick_params(axis='both', which='both', \n",
    "                            top=False, bottom=False, left=False, right=False,\n",
    "                           labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        label_to_str = lambda label: \"Yes\" if label == 1 else \"No\"\n",
    "        plt.suptitle(f\"Brain Tumor: {label_to_str(label)}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe17679",
   "metadata": {},
   "source": [
    "### Spliting the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688e9cb3",
   "metadata": {},
   "source": [
    "Spliting the data into train, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff174ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.2):\n",
    "       \n",
    "    X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=test_size)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbeab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eee01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of development examples = \" + str(X_val.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(y_train.shape))\n",
    "print (\"X_val (dev) shape: \" + str(X_val.shape))\n",
    "print (\"Y_val (dev) shape: \" + str(y_val.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce0557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return f\"{h}:{m}:{round(s,1)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8034d88",
   "metadata": {},
   "source": [
    "Converting the vector of probabilities to a target vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cc003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1_score(y_true, prob):\n",
    "    \n",
    "    y_pred = np.where(prob > 0.5, 1, 0)    \n",
    "    score = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4bca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "\n",
    "    X_input = Input(input_shape) \n",
    "    X = ZeroPadding2D((2, 2))(X_input) \n",
    "    X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X) \n",
    "    X = MaxPooling2D((4, 4), name='max_pool0')(X) \n",
    "    X = MaxPooling2D((4, 4), name='max_pool1')(X) \n",
    "    X = Flatten()(X) \n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X) \n",
    "    model = Model(inputs = X_input, outputs = X, name='BrainDetectionModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801e51f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMG_WIDTH, IMG_HEIGHT, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe78a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(IMG_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85844294",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dc5324",
   "metadata": {},
   "source": [
    "Specifying loss function and optimizer to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d972508",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40ba11a",
   "metadata": {},
   "source": [
    "### Training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22c8650",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_name = f'brain_tumor_detection_cnn_{int(time.time())}'\n",
    "tensorboard = TensorBoard(log_dir=f'logs/{log_file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253f3789",
   "metadata": {},
   "source": [
    "Saving the model with the best validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf450c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"cnn-parameters-improvement-{epoch:02d}-{val_acc:.2f}\"\n",
    "checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178067ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.fit(x=X_train, y=y_train, batch_size=32, epochs=10, validation_data=(X_val, y_val), callbacks=[tensorboard, checkpoint])\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)\n",
    "print(f\"Elapsed time: {hms_string(execution_time)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbf826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.fit(x=X_train, y=y_train, batch_size=32, epochs=3, validation_data=(X_val, y_val), callbacks=[tensorboard, checkpoint])\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)\n",
    "print(f\"Elapsed time: {hms_string(execution_time)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155f8e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.fit(x=X_train, y=y_train, batch_size=32, epochs=5, validation_data=(X_val, y_val), callbacks=[tensorboard, checkpoint])\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)\n",
    "print(f\"Elapsed time: {hms_string(execution_time)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8888b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1cac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in history.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481bfddb",
   "metadata": {},
   "source": [
    "### Ploting Loss and Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab2723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    \n",
    "    train_loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "    train_acc = history['acc']\n",
    "    val_acc = history['val_acc']\n",
    "    \n",
    "    # Loss\n",
    "    plt.figure()\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Accuracy\n",
    "    plt.figure()\n",
    "    plt.plot(train_acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30b84de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3453a158",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1d18fe",
   "metadata": {},
   "source": [
    "Choosing the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c13d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(filepath='models/cnn-parameters-improvement-23-0.91.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aad49c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f952c2",
   "metadata": {},
   "source": [
    "Evaluating the best model on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbbb793",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = best_model.evaluate(x=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5545a6",
   "metadata": {},
   "source": [
    "Accuracy of the best model on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb29f5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"Test Loss = {loss}\")\n",
    "print (f\"Test Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77343ed2",
   "metadata": {},
   "source": [
    "F1 Score of the best model on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673742eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee05e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1score = compute_f1_score(y_test, y_test_prob)\n",
    " print(f\"F1 score: {f1score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4019b7",
   "metadata": {},
   "source": [
    "F1 Score on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c8b49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_prob = best_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f8335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1score_val = compute_f1_score(y_val, y_val_prob)\n",
    "print(f\"F1 score: {f1score_val}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
